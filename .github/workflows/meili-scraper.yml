name: Scrape MeiliSearch index

on:
  push:
    branches:
      - main

  # 手动触发
  workflow_dispatch:

  # 定时任务：每天凌晨 02:00（北京时间 = UTC+8 => UTC 18:00）
  schedule:
    - cron: "0 18 * * *"

# 防止同一时间多次触发（push + schedule）造成并发写索引
concurrency:
  group: meili-scrape-${{ github.ref }}
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      # --- 正式运行 docs-scraper ---
      - name: Run Meili docs-scraper
        env:
          MEILISEARCH_HOST_URL: ${{ secrets.MEILISEARCH_HOST_URL }}
          MEILISEARCH_API_KEY: ${{ secrets.MEILISEARCH_MASTER_KEY }}
          CONFIG_FILE_PATH: ${{ github.workspace }}/wiki/.vuepress/meili-scraper.json
        run: |
          set -e
          echo "Config file: $CONFIG_FILE_PATH"
          test -f "$CONFIG_FILE_PATH"

          docker run -t --rm \
            -e MEILISEARCH_HOST_URL \
            -e MEILISEARCH_API_KEY \
            -v "$CONFIG_FILE_PATH:/docs-scraper/config.json" \
            getmeili/docs-scraper:latest \
            pipenv run ./docs_scraper config.json
